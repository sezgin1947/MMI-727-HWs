{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "hw2_Question 3_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALYv9MueCwsn",
        "colab_type": "text"
      },
      "source": [
        "# 3. Convolutional Neural Networks (60 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpk-UgW9Cwsn",
        "colab_type": "text"
      },
      "source": [
        "### Implement the convolutional neural network shown below for CIFAR-10 dataset.  Your code must follow these rules:\n",
        "\n",
        "__- Use your own implementation.__\n",
        "\n",
        "__- You can only use \" tf \" and \" tf.nn \" libraries for version 1 (40 pts). Check [tf.nn](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/nn)__\n",
        "\n",
        "__- You can use \" tf.layers \" library for version 2 (20 pts). Check [tf.layers](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/layers)__\n",
        "\n",
        "__- Use ReLU activation function__\n",
        "\n",
        "__- Use batch normalization for convolutional layers__\n",
        "\n",
        "__- Use dropout for fully connected layers (for training only)__\n",
        "\n",
        "__- Write necessary explanations for each cell. Explanations should be detailed.__\n",
        "\n",
        "__- You can use codes from Lab Notebook.__\n",
        "\n",
        "__- (OPTIONAL) You can add more layers or use different methods for better accuracy. If you want, send an another notebook file with better accuracy for bonus points.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5bOUxQKCwso",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/METU-MMI-DeepLearning/MMI713_Deep_Learning/blob/master/Assignment%202/model.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE3ltKqWCwsp",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqgg8OMlCwsp",
        "colab_type": "code",
        "outputId": "634a0392-fad9-45df-e74d-479b223f75dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEOoMK_ZCwsr",
        "colab_type": "text"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "You can normalize input data \"x\" if needed. You can use \"np.squeeze\" to remove single-dimensional entries from the shape of an array. You probably need to convert labels \"y\" to one-hot vector for loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YL3QdYjCwsr",
        "colab_type": "code",
        "outputId": "b617a833-f655-484f-c8d6-29259f0d41c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape)\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255   # place input values between 0-1\n",
        "\n",
        "y_train = tf.one_hot(np.squeeze(y_train),10)  #implement one-hot dec. for labels\n",
        "y_test = tf.one_hot(np.squeeze(y_test),10)\n",
        "y_train_cls = tf.argmax(y_train, axis=1)  #get the classes as single guesses\n",
        "y_test_cls = tf.argmax(y_test, axis=1)\n",
        "\n",
        "session = tf.Session()  \n",
        "y_train = y_train.eval(session=session) #datatype conversion from tensor to np.ndarray\n",
        "y_train_cls = y_train_cls.eval(session=session)\n",
        "y_test = y_test.eval(session=session)\n",
        "y_test_cls = y_test_cls.eval(session=session)\n",
        "\n",
        "x_train = x_train.astype(np.float32)  #placeholders are float32 hence, convert them\n",
        "x_test = x_test.astype(np.float32)\n",
        "print(type(x_train[0,1,1,1])) #debug prints\n",
        "print(type(x_test[0,1,17,1]))\n",
        "print(type(y_train[0,1]))\n",
        "print(type(y_test[0,1]))\n",
        "print(type(y_test_cls[0]))\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_test_cls.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "<class 'numpy.float32'>\n",
            "<class 'numpy.float32'>\n",
            "<class 'numpy.float32'>\n",
            "<class 'numpy.float32'>\n",
            "<class 'numpy.int64'>\n",
            "(50000, 10)\n",
            "(10000, 10)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7gS1DR4Cwst",
        "colab_type": "text"
      },
      "source": [
        "## Define placeholders\n",
        "\n",
        "Define input and output placeholders. It is a good idea to pass dropout rate also as a placeholder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2NkMH2HCwsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, 32,32,3]) #placeholder for input\n",
        "y_true = tf.placeholder(tf.float32, [None, 10]) #placeholder for label in order to use in error mtrx. calc.\n",
        "y_true_cls = tf.placeholder(tf.int64, [None]) #placeholder for class guesses\n",
        "dropout_rate = tf.placeholder(tf.float32) #dropout rate\n",
        "training_flag = tf.placeholder(tf.bool)  # flag for test and training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRPDkWo4Cwsv",
        "colab_type": "text"
      },
      "source": [
        "## Define variables\n",
        "\n",
        "Define filters for convolutional layers, weights and biases for fully connected layers. Don't forget to use a initializer. Xavier is recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Tx0QNyCwsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv1 = tf.get_variable(\"conv1\", shape=[5,5,3,32], initializer=tf.glorot_normal_initializer())\n",
        "padding_conv1 = \"SAME\"\n",
        "stride_conv1 = [1,1]  #1st conv layer, filters have size 5x5x3. 32 filters in this layer\n",
        "\n",
        "window1 = [3,3]   #1st pooling layer\n",
        "padding_pool1 =\"SAME\"\n",
        "pooling_type1 = \"AVG\" #average pooling\n",
        "stride_pool1 =  [2,2] #stride size 2 in each direction\n",
        "\n",
        "conv2 = tf.get_variable(\"conv2\", shape=[5,5,32,16], initializer=tf.glorot_normal_initializer())\n",
        "padding_conv2 = \"SAME\"\n",
        "stride_conv2 = [1,1]  #2nd conv layer filters sized 5x5x32, 16 total filters\n",
        "\n",
        "window2 = [3,3]\n",
        "padding_pool2 = \"SAME\"\n",
        "pooling_type2 = \"AVG\"\n",
        "stride_pool2 = [2,2]  #2nd pooling layer\n",
        "\n",
        "conv3 = tf.get_variable(\"conv3\", shape=[5,5,16,32], initializer=tf.glorot_normal_initializer())\n",
        "padding_conv3 = \"SAME\"\n",
        "stride_conv3 = [1,1]  #3rd conv layer\n",
        "\n",
        "window3 = [3,3]\n",
        "padding_pool3 = \"SAME\"\n",
        "pooling_type3 = \"AVG\"\n",
        "stride_pool3 = [2,2]  #3rd pooling layer\n",
        "\n",
        "#weights1 = tf.get_variable(\"weights1\", shape=(32*4*4,128), initializer = tf.random_normal_initializer())\n",
        "#weights2 = tf.get_variable(\"weights2\", shape=(128,10), initializer = tf.random_normal_initializer())\n",
        "weights1 = tf.Variable(tf.random.uniform([32*4*4,128])) #weights for 1st fc layer\n",
        "weights2 = tf.Variable(tf.random.uniform([128,10])) # weights for 2nd fc layer\n",
        "#bias1 = tf.get_variable(\"bias1\", shape= (128), initializer = tf.zeros_initializer())\n",
        "#bias2 = tf.get_variable(\"bias2\", shape= (10), initializer = tf.zeros_initializer())\n",
        "bias1 = tf.Variable(tf.zeros([128]))  #biases of first fc layer\n",
        "bias2 = tf.Variable(tf.zeros([10]))   # biases of second fc layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D7ZiydvCwsx",
        "colab_type": "text"
      },
      "source": [
        "## Define network\n",
        "\n",
        "Define the network as a function.Recommended functions are:\n",
        "\n",
        "`\n",
        "tf.nn.convolution / tf.nn.pool / tf.nn.batch_normalization / tf.nn.dropout / tf.reshape`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uglLHBb7Cwsx",
        "colab_type": "code",
        "outputId": "65a1ca51-69b4-46a7-c0ec-20bf6e639998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "def netw0rk(x,dropout_rate,training_flag):\n",
        "    nn_1 = tf.layers.conv2d(x, 32, [5,5], [1,1], padding=\"SAME\", #5x5 spatial size filters, 32 total filters, stride 1.\n",
        "                          kernel_initializer= tf.contrib.layers.xavier_initializer()) #filters init. with xavier init.\n",
        "    nn_2 = tf.contrib.layers.batch_norm(nn_1) # batch normalization\n",
        "    nn_3 = tf.nn.relu(nn_2) # relut activation layer\n",
        "    nn_4 = tf.layers.average_pooling2d(nn_3, pool_size=[3,3], strides=[2,2], padding=\"SAME\") #average pooling with 3,3 window and 2,2 stride size\n",
        "\n",
        "    nn_5 = tf.layers.conv2d(nn_4, 16, [5,5], [1,1], padding=\"SAME\",\n",
        "                          kernel_initializer= tf.contrib.layers.xavier_initializer())\n",
        "    nn_6 = tf.contrib.layers.batch_norm(nn_5)\n",
        "    nn_7 = tf.nn.relu(nn_6)\n",
        "    nn_8 = tf.layers.average_pooling2d(nn_7, pool_size=[3,3], strides=[2,2], padding=\"SAME\")\n",
        "\n",
        "    nn_9 = tf.layers.conv2d(nn_8, 32, [5,5], [1,1], padding=\"SAME\",\n",
        "                          kernel_initializer= tf.contrib.layers.xavier_initializer())\n",
        "    nn_10 = tf.contrib.layers.batch_norm(nn_9)\n",
        "    nn_11 = tf.nn.relu(nn_10)\n",
        "    nn_12 = tf.layers.average_pooling2d(nn_11, pool_size=[3,3], strides=[2,2], padding=\"SAME\")\n",
        "\n",
        "    nn_13 = tf.contrib.layers.flatten(nn_12)\n",
        "\n",
        "    nn_14 = tf.layers.dense(nn_13,128)\n",
        "    nn_15 = tf.layers.dropout(nn_14, rate = dropout_rate, training=training_flag)\n",
        "    nn_16 = tf.nn.relu(nn_15)\n",
        "    nn_17 = tf.layers.dense(nn_16,10)\n",
        "    return  nn_17\n",
        "\n",
        "logits = netw0rk(x, dropout_rate, training_flag)  \n",
        "y_pred = tf.nn.softmax(logits)  #calculate output pred.\n",
        "y_pred_cls = tf.argmax(y_pred, axis=1)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From <ipython-input-5-cc01a905bac3>:3: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.Conv2D` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-cc01a905bac3>:6: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.AveragePooling2D instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-cc01a905bac3>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From <ipython-input-5-cc01a905bac3>:23: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dropout instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYHUDRlVCwsz",
        "colab_type": "text"
      },
      "source": [
        "## Define cost function\n",
        "\n",
        "Define cost with respect to predictions and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3y1d0C0Cwsz",
        "colab_type": "code",
        "outputId": "5cd1335f-fcc4-4200-d853-396f2d837d08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,    #calc. loss between result and labels\n",
        "                                                        labels=y_true)\n",
        "cost = tf.reduce_mean(cross_entropy)  #cost function"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-6-5e5775ad1444>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51EwRVaNCws1",
        "colab_type": "text"
      },
      "source": [
        "## Define optimizer\n",
        "\n",
        "Adam is recommended"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7_ZeOlTCws1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(learning_rate=0.0005).minimize(cost) #adam optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9D4Ook2Cws2",
        "colab_type": "text"
      },
      "source": [
        "## Define performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDNLQR0_Cws3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))  #data flow elements for perf. measurement"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CWFb6DECws4",
        "colab_type": "text"
      },
      "source": [
        "## Create TensorFlow session\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxmAkz_2Cws5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#session = tf.Session() # commented since already started in 1st cell"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiFHxELICws7",
        "colab_type": "text"
      },
      "source": [
        "## Initialize variables\n",
        "\n",
        "The variables for `weights`,`filters` and `biases` must be initialized before we start optimizing them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XV9pysJCws7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F_36zpCCws9",
        "colab_type": "text"
      },
      "source": [
        "## Define train function\n",
        "\n",
        "Don't forget to use batches since dataset is large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q6PSUYpCws9",
        "colab_type": "text"
      },
      "source": [
        "Hint : One of the simplest way to define batch is\n",
        "\n",
        "`for b in range(dataset_size//batch_size):      \n",
        "    x_batch = x_train[b * batch_size : (b+1) * batch_size]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDrXnOiDE-TO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(batch_size = 100):\n",
        "    correct_pred_array = []\n",
        "    for b in range(x_train.shape[0]//batch_size):      \n",
        "        x_batch = x_train[b * batch_size : (b+1) * batch_size]\n",
        "        y_true_batch = y_train[b * batch_size : (b+1) * batch_size, :]\n",
        "        y_train_cls_batch = y_train_cls[b * batch_size : (b+1) * batch_size]  # Class pred also fed in order to get accuracy for train_acc graph\n",
        "        feed_dict_train = {x: x_batch,\n",
        "                          y_true: y_true_batch,\n",
        "                          dropout_rate : 0.4,\n",
        "                          training_flag : True}\n",
        "        opt, cls_pred = session.run([optimizer, y_pred_cls], feed_dict=feed_dict_train)\n",
        "        # Run the model to get predictions for test data\n",
        "        # Get true labels\n",
        "        cls_true = y_train_cls_batch\n",
        "        # Calculate the difference betweeb predictions and true labels\n",
        "        correct_prediction = np.equal(cls_pred, cls_true)\n",
        "        correct_pred_array.append( np.mean(correct_prediction))\n",
        "        # Calculate the total accuracy\n",
        "        \n",
        "    return np.mean(correct_pred_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhxmS0YlCws_",
        "colab_type": "text"
      },
      "source": [
        "## Define test function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDQQNV3-CwtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feed_dict_test = {x: x_test,    #feed placeholders with proper variables.\n",
        "                  y_true: y_test,\n",
        "                  y_true_cls: y_test_cls,\n",
        "                  dropout_rate : 0.01,\n",
        "                  training_flag : False}  #test_training = 0 network should work for inference not for training\n",
        "def test():\n",
        "    # Run the model to get predictions for test data\n",
        "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
        "    \n",
        "    # Get true labels\n",
        "    cls_true = y_test_cls\n",
        "    \n",
        "    # Calculate the difference betweeb predictions and true labels\n",
        "    correct_prediction = np.equal(cls_pred, cls_true)\n",
        "    \n",
        "    # Calculate the total accuracy\n",
        "    acc = np.mean(correct_prediction)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJaf9rtzTFLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-McO8NLyCwtB",
        "colab_type": "text"
      },
      "source": [
        "## Performance before training\n",
        "\n",
        "The accuracy is expected to be around 10%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoG4lkKLCwtC",
        "colab_type": "code",
        "outputId": "a4190782-29e3-415f-b17c-f01a75aa4389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9h8MDSzCwtD",
        "colab_type": "text"
      },
      "source": [
        "## Performance after training\n",
        "\n",
        "Measure training and test accuracy for at least 10 epochs, show it on a epoch/accuracy graph. The network is expected to reach around 70% accuracy at 10 epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmRzcvlmCwtD",
        "colab_type": "code",
        "outputId": "1bd831d7-fad2-42b9-b426-cd4551f193b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "epoch_number = 20\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "for a in range (epoch_number):\n",
        "    train_acc.append(train(batch_size = 128))\n",
        "    test_acc.append(test())\n",
        "print(\"final train acc : \")\n",
        "print(train_acc[-1])\n",
        "print(\"final test_acc : \")\n",
        "print(test_acc[-1])\n",
        "k = np.linspace(1,epoch_number,epoch_number)\n",
        "\n",
        "plt.plot(k,train_acc) #plot train and test accuracy graphs\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy on Training Data\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(k,test_acc)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy on Test Data\")\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final train acc : \n",
            "0.7686899038461539\n",
            "final test_acc : \n",
            "0.7399\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxV9Z3/8deHEPaQBJKwhRCWgAIu\nQNS6YxWKtmJbpx10Hq3WtowdtXaztfNrOx27uMxmnTqd0g7Wtrba1dIpShWxdloXEmSRfZFAwhIg\nCwGy5/P7457gNd4kB8i9N8v7+Xjcx73ne77nns+93JwP53zP9/s1d0dERKStfskOQEREuiclCBER\niUkJQkREYlKCEBGRmJQgREQkpv7JDqCrZGVleX5+frLDEBHpUYqLiw+7e3asdb0mQeTn51NUVJTs\nMEREehQzK2lvnS4xiYhITEoQIiISkxKEiIjEpAQhIiIxKUGIiEhMShAiIhKTEoSIiMTUa/pBiIj0\nFe7OoZp6th08xraDNQxM7cffXTShy/ejBCEi0o0dPlbPtoM1bA+SwfaDx9hWXkPVicaTdWbnZShB\niIj0VhXHG4IEUHPyzGB7+TEqjjecrDN8UH+mjkrj2pljmDpqGFNHpVEwahjZwwbGJSYlCBGRLtbS\n4tTUN1F9opHKEw1U1TZSdaKBqhONVAVl1bXBuhONlFae4PCxtxJB2sD+FIwaxvzpoygYlXYyGeSk\nDcTMEvY5lCBERE5RQ1ML2w7WsHFfNW+UHaWsqvatBFDbSHVtI80t7U/nnDawPxlDU8kYPICMIam8\n+6yc4GwgkgxGDx+U0ETQHiUIEZEO1DY0s/nAUTaWRZLBxv3VbD1QQ2NzJAEMG9ifvBFDyByaypiM\nwWQMTiVzSOTAnzFkQGR5aCrpQTJIH5xKakrPuIFUCUJEJFBT18imfUd5Y1+QEPZVs6P8GK0nAxlD\nUjlnXDq3XTaRmWPTmTkunQkjhtCvX/L/tx8PShAi0ue0tDhlVbVsPVDD1oM1bNp/lE37jvLm4eMn\n6+SkDWTmuHQWzBjNjHGRZDA2vXtc+kmUuCYIM1sAfAdIAX7o7g+0Wf8fwFXB4hAgx90zgnXNwIZg\n3R53XxjPWEWk93F3Dh2rZ9uBY2w9WMO2ICFsP1jD8Ybmk/XGZQzmnHHp3Dh7HDPGpTNj7HBy0gYl\nMfLuIW4JwsxSgEeBeUApsNrMlrn7ptY67v7ZqPp3AbOi3qLW3c+PV3wi0rtUn2hkW3kNWw/UsO3g\nW8+VUf0FsoYNYOqoND5UOJ5po9NO3iY6fFBqEiPvvuJ5BnEhsMPddwGY2ZPADcCmdurfBPxTHOMR\nkV7iaF0j6/dW8/qeSl7fW8WmfUc5cLTu5PphA/szddQwFswczbRRaUwNkkFWnPoL9FbxTBDjgL1R\ny6XARbEqmtkEYCLwQlTxIDMrApqAB9z96RjbLQYWA+Tl5XVR2CLSnTS3ODvKj0WSwZ4qXt9byfby\nY3jQcFyQM4yLJ49k2ui0k8mgr7UVxEt3aaReBPzK3Zujyia4e5mZTQJeMLMN7r4zeiN3XwIsASgs\nLGz/pmMR6TEqjjewdm8kGazZU8m6vdUcq28CIncRzRqfwfvOHcusvAzOzc0gfbAuD8VLPBNEGTA+\najk3KItlEXBHdIG7lwXPu8zsRSLtEzvfuamI9ERNzS2U19RTVlXL5v1HI2cHeyrZfeQEACn9jLPH\npPGBWeOYlZfBrLxM8kcO0ZlBAsUzQawGCsxsIpHEsAi4uW0lMzsLyARejirLBE64e72ZZQGXAg/F\nMVYR6WI1dY3sq6pjX1UtZVW17Asekdd1HDha97bextlpA5mdl8GiC/OYNT5ydjB4QEoSP4HELUG4\ne5OZ3QmsIHKb61J332hm9wFF7r4sqLoIeNLdoy8RnQ1838xaiMxZ8UD03U8i0j0cPFrH63uqePPw\n8TYJoJajdU1vq9u/nzEmYxBj0wdz0cQRjM0YzNiMwYzLHMzk7KGMyxiss4Nuxt5+XO65CgsLvaio\nKNlhiPRadY3NvFFWzdq9VScvB+2rfuvOofTBqZEDfsagtw7+Uc/ZaQNJ6aU9jnsyMyt298JY67pL\nI7WIdCPuTsmRE7weNBavDW4lbQouCY3LGMzsCZl8PC+T88dnMHXUMNLUl6DXUYIQEaprG1lf+taZ\nwdq9VSc7mA0ZkMJ5uRl88opJzBqfwfl5Gepl3EcoQYj0Qc0tzrrSKlZuPsjKzeVsOVADgBlMyR7G\nvOmjmHXy7CBNl4b6KCUIkT7iWH0T/7f9EM9vLmfVlnKOHG8gpZ9ROCGTz8+byqy8TM4dn65hJ+Qk\nJQiRXmxvxQle2FLO85sP8uquChqaWxg+qD9zp+Vw9dk5zJ2aQ/oQJQSJTQlCpBdpbnHW7q1k5eZy\nVm4uZ+vByKWjSVlDueWSCVx99ijmTMjsMRPWSHIpQYj0YO5O1YlGXt51hJWby1m1tZyK4NLRBfmZ\nfOW9Z/Pus3KYlD0s2aFKD6QEIdKNuTuHjzVQVlVLWWUtpZUnTr4uq6qltLL25DhF6YNTmTstm6vP\nHsWVBdm6dCRnTAlCJMkqjjew89CxqIP+CUor3+qRXNfY8rb6aYP6k5s5hNzMIbxr0sjIZDe56RRO\nyKS/Lh1JF1KCEEmwlhZnQ1k1q7aWs2rrIdaXVhE9oMHIoQPIzRzMWaPTuPqsHMZlDCY3cwjjMiPD\nUuguI0kUJQiRBKiubeTP2w+xassh/rStnMPHGjCD88dn8NlrpnJubnokCWQM1gB10m0oQYjEgbuz\n9WANq7YcYtXWcopLKmlucTKGpHLl1GyumpbDFVOzGTF0QLJDFWmXEoRIFzle38Rfdx5h1dZyXtxS\nfnIgu+ljhvOpKydz1VnZnD8+U72SpcdQghA5A+U1dSxfv5+VW8pPdkQbNrA/l03J4u5rsrlyag6j\n0zVukfRMShAip6j6RCPPvLGfZev28cquI7Q4TM6OdES7aloOhfkjGNBfdxNJz6cEIRLC8fomnt98\nkGVr9/HS9kM0Njv5I4dw51VTuP68sRSMSkt2iCJdTglCpB31Tc28uPUQy9btY+Xmg9Q1tjAmfRC3\nXpLPwvPGMXPccM2AJr2aEoRIlKbmFv668wi/X7ePZzceoKauiRFDB/A3c3JZeN44Cidk0k+NzNJH\nKEFIn9fS4hTvqeT36/axfMN+Dh9rIG1gf+bPGM31543h0ilZGtxO+qROE4SZZQFfAKYDJ2/HcPf5\nIbZdAHwHSAF+6O4PtFn/H8BVweIQIMfdM4J1twBfCdZ9090f7/TTiITk7ry+t4rl6/ezfMN+9lXX\nMbB/P645exTXnzeGudNyGJSqDmvSt4U5g/gp8Fvg/cAdwC3Agc42MrMU4FFgHlAKrDazZe6+qbWO\nu382qv5dwKzg9Qjgn4BCwIHiYNvKkJ9L5B3cnbV7q1i+YT/LNxygrKqW1BTjioJs7lkwjXnTRzNs\noE6qRVqF+WvIdvfvm9kd7r7SzF4AXg2x3YXADnffBWBmTwI3AJvaqX8TkaQA8B7gOXevCLZ9DlgA\n/DzEfkVOcnfWlVazfMN+/rB+/8mkcHlBNp+bN5Vrpo8ifbDGNhKJJUyCaAyeD5jZe4B9wMgQ240D\n9kYtlwIXxapoZhOAicALHWw7LsZ2i4HFAHl5eSFCkr7A3VnfmhQ27Ke0MpIULpuSxWfnTWWekoJI\nKGESxLfNLJ1IO8SjwPDgdVdaBPzK3ZtPZSN3XwIsASgsLPROqksv5h4ZIfUPwZlCaWUt/fsZlxVk\ncffVBcyfPlrzI4icojAJotzdq4H1wOUAZvauENuVAeOjlnODslgWEWnfiN52bpttXwyxT+lj9lfX\n8sQre/jdujL2VkSSwqVTsvj01QXMnz6KjCEaDE/kdIVJEP8FzG5T9igwp5PtVgMFZjaRyAF/EXBz\n20pmdhaQCbwcVbyCyJlLZrA8H/hyiFilj1izp5Kl//cmz7xxAHfn0ilZ3HVVAfNnKCmIdJV2E4SZ\nXQhcDGSb2aejVg0HOj1Xd/cmM7uTyME+BVjq7hvN7D6gyN2XBVUXAU+6vzVlirtXmNk3iCQZgPta\nG6yl72psbmH5hv089pfdrN1bRdqg/tx2aT4fvTif8SOGJDs8kV6nozOIoUBWUCc7qrwG+FCYN3f3\n5cDyNmVfa7P89Xa2XQosDbMf6d0qjzfws9f28JOXSzhwtI6JWUO574YZ3Dg7l6G6LVUkbtr963L3\nVcAqM3us9VZVkUTadrCGx/7yJr9ZU0Z9UwuXF2Tx7Q/OZO7UHA13IZIAYf77ddTM7gdmcIo9qUVO\nVUuL86dth1j6lzf58/bDDOzfjw/OHsetl0xk2miNmCqSSKfSk/oDnEJPapFTcby+iV+vKeVHf9nN\nrsPHGTV8IPe8Zxo3XZinaTlFkiSePalFOlV1ooHv/WknP3t1DzV1TZw3PoPvLDqf684ZowHyRJIs\nnj2pRdrV0NTCj1/ezX++sIOjdY1cd84YPn7ZRGbnZXa6rYgkxun2pL4nrlFJr+XuPPvGAR54dgsl\nR05weUEW/3jd2Zw9ZniyQxORNjpNEFH9FU72pBY5Ha/vqeRbf9hMUUklU0cN40cfu4C503KSHZaI\ntKPDBGFmlwN3AmcFRZuB77r7/8U7MOk99lac4MFnt/C/6/eTNWwg93/wHD40J5f+amMQ6dY66kl9\nLfA94FvAQ4ARGXLjJ2Z2u7uvSEyI0lNV1zbyX6t28NhfdtOvH3z63VNYfOVkzbkg0kN09Jf6ReAD\n7v56VFmRmb0GPExkCA2Rd2hsbuGJV0r4zsrtVNU2cuPsXD4/fypj0gcnOzQROQUdJYixbZIDAO6+\n1sxGxzEm6aHcnT9uOsgDz2zhzcPHuWTySP7xurOZOS492aGJyGnoKEEc62Dd8a4ORHq29aVVfPMP\nm3ntzQqm5Axj6a2FXDUtBzMNiSHSU3WUICab2W9ilBswKU7xSA9TfrSO+5/Zwm9fL2Pk0AF88/0z\nWXTBeDVAi/QCHSWIGztY992uDkR6lqbmFn701908/Px2Gppb+Ie5k/nU3MmkDdKsbSK9RUejua5M\nZCDSc7z2ZgVf+90bbDlQw9xp2Xz9+hnkZw1Ndlgi0sV0v6GEdqimnvuf2cxv1pQxLmMw3//IHOZP\nH6V2BpFeSglCOtXU3MJPXynh3/64jbqmZu64ajJ3XDWFIQP08xHpzfQXLh0qLqngq09vZNP+o1xe\nkMU/L5zBpOxhyQ5LRBKg0wRhZr8FvE1xNVAE/MDdGzrYdgHwHSJzUv/Q3R+IUefDwNeDfaxz95uD\n8mZgQ1Btj7sv7PTTSJc5fKyeB5/Zwi+LSxmTPoj/+rvZXDtztC4nifQhYc4g9gKjgZ8Hy38L1AHn\nAj8gMoHQO5hZCpHRX+cBpcBqM1vm7pui6hQAXwYudfdKM4seua3W3c8/xc8jZ6i5xfnZa3v4l2e3\ncKKhmduvnMxd756iuZ9F+qAwf/UXu/sFrQtm9jTwmrtfYGabOtjuQmBH63zWZvYkcAMQvc0ngUfd\nvRLA3ctP9QNI11m7t4qvPv0GG8qquXjSSL7x/hlMydE0nyJ9VZgEkWZmue5eGiyPBVqPGvUdbDeO\nyNlHq1LgojZ1pgKY2V+IXIb6urs/G6wbZGZFQBPwgLs/3XYHZrYYWAyQl5cX4qNILJXHG3hoxRae\nXL2X7GEDeeSmWVx/7hhdThLp48IkiC8CL5vZFiK9qKcCd5rZUOCJLth/ATAXyAVeMrNz3L0KmODu\nZWY2CXjBzDa4+87ojd19CbAEoLCwsG07iYSwencFt/+kmKraRj5x2UTuvmaqRlsVESDkhEFm9hww\nPSja5O61wet/7WDTMmB81HJuUBatFHjV3RuBN81sG5GEsdrdy4L97zKzF4FZwE6ky/yyaC//+NsN\n5GYO4YlPXsRZozWrm4i8JeyAOecAk4FpwAfM7OYQ26wGCsxsopkNABYBy9rUeZrI2QNmlkXk7GSX\nmWWa2cCo8kt5e9uFnIGWFuf+ZzZzz6/Wc0H+CJ7+h0uVHETkHcLc5vojImcPa4HmoNiBn3W0nbs3\nmdmdROaNSAGWuvtGM7sPKAqmMl0BzA8au5uBe9z9iJldAnzfzFqIJLEHou9+ktN3vL6Jzzy1luc2\nHeTmi/L454UzSNXAeiISg7l3fOk+aHuY7u4tiQnp9BQWFnpRUVGyw+jWyqpq+cTjRWw9cJSvvW86\nt1ySr4ZokT7OzIrdvTDWujCtkRuBbOBgl0YlCfX6nko++eNi6hubWXrrBcydltP5RiLSp4VJEOnA\nJjN7hajbWt39g3GLSrrUsnX7+MIv1zF6+CB+/smLKBilvg0i0rkwCeL+uEchcdHS4jy8cjuPrNzO\nhfkj+O+PzGHE0AHJDktEeogwt7lqXogeqLahmS/8ah1/WL+fD83J5ZsfmMnA/inJDktEepB2E4SZ\n/cndrzSzSt4+WJ8B7u4j4h6dnJbyo3V88sdFrC+r5svXnsXiKyapMVpETllHZxBXBc9ZiQhEusYb\nZdV84vEijtY1suQjhcybPirZIYlID9XRlKMtwXOzRf77md2m/r44xyan6Nk39vPZp9aROSSVX91+\nCdPHqvObiJy+MB3l/gG4DzgCtPaFcN4aekOSzN35rxd38i8rtjIrL4Pvf2QOOWmDkh2WiPRwYe5i\n+hxwtrsfincwcuqaW5wv/mo9v15Tyg3nj+XBG89lUKoao0XkzIVJEKVARbwDkVPn7vzz7zfy6zWl\nfOaaAu6+ukCN0SLSZcIkiB1Ehtv+X97eUe6RuEUloSx5aRc/frmEv79iEp+5ZmqywxGRXiZMgtgf\nPNTi2Y38bm0Z9z+zhevPG8uXFpyV7HBEpBcK01Huq4kIRMJ7eecR7vnlei6aOIJ//dC59Ouny0oi\n0vU66ij3b+7+eTP7LW/vKAdoLKZk2XawhsU/KWLCyCEs+UihekeLSNx0dAbxVPD83UQEIp07eLSO\nW5e+xuDUFH5024WkD0lNdkgi0ot11FHuteBZYzF1AzV1jdz62Gqqaxv5xe0XMy5jcLJDEpFeLkxH\nucnAt4h0jDvZ+8rdddtMgjQ0tfCpn65h+8Ealt56ATPGpic7JBHpA8LMNfkj4DEig/RdC/yCty4/\nSZy5O/f+Zj3/t+Mw93/wHK6Ymp3skESkjwiTIIa4+woAd9/p7l8hkigkAf7juW38Zk0Zn5s3lQ8V\njk92OCLSh4RJEPVm1g/YaWa3m9n1QKgpycxsgZltNbMdZnZvO3U+bGabzGyjmf0sqvwWM9sePG4J\n9Wl6mZ+/todHXtjBogvGc9e7pyQ7HBHpY8J0lPssMBT4NJG2iOHAbZ1tZGYpwKPAPCLDdaw2s2Xu\nvimqTgHwZeBSd680s5ygfATwT0AhkVtsi4NtK0/lw/Vkq7aU85Wn32DutGy+8f6ZGkJDRBKuwwQR\nHOQ/4O6vAjXAR07hvS8Edrj7ruC9ngRuADZF1fkk8Gjrgd/dy4Py9wDPuXtFsO1zwALg56ew/x5r\nfWkV//DEGs4ek8ajN88mNSXMiZ6ISNfq8Mjj7s28NXHQqRoH7I1aLg3Kok0FpprZX8zsFTNbcArb\nYmaLzazIzIoOHeodg83uOXKC2360mpHDBrD01gsYOjDMSZ6ISNcLc/QpNrPfAL8EjrcWuvuyLtp/\nATAXyAVeMrNzwm7s7kuAJQCFhYXv6O3d01Qeb+DWx16jsdl5cvGFmtNBRJIqTIJII5IYrosqc6Cz\nBFEGRN92kxuURSsFXnX3RuBNM9tGJGGUEUka0du+GCLWHquusZlP/LiI0qpanvjERUzJGZbskESk\nj+toLKY73f277n4q7Q7RVgMFZjaRyAF/EXBzmzpPAzcBj5lZFpFLTruAncC3zSwzqDefSGN2r9Tc\n4nzmybWs2VPJozfP5oL8EckOSUSkwzaITu9U6oi7NwF3AiuAzcAv3H2jmd1nZguDaiuAI2a2CVgF\n3OPuR4LG6W8QSTKrgftaG6x7o2/9YTPPbjzAV947nevOGZPscEREADD32JfuzWyNu89OcDynrbCw\n0IuKipIdxil7ZdcRFi15hVsvyefrC2ckOxwR6WPMrNjdC2Ot66gN4lwzOxrr/QB3d00gdIbcnfuf\n2cKY9EHce60m/RGR7qWjBLHB3WclLJI+aPmGA6zbW8VDf3Mug1I1r4OIdC/qgZUkDU0tPLRiC9NG\npXHj7NxkhyMi8g4dJYhfJiyKPujnr+2h5MgJ7r32LFI0ZaiIdEPtJgh3/3YiA+lLauoa+c7K7Vw8\naSRzp2n4bhHpnnSJKQmWvLSLiuMNfPm6szQIn4h0W0oQCXbwaB0/+PMurj9vLOfmZiQ7HBGRdoWZ\ncnQgcCOQH13f3e+LX1i918PPb6O5xbln/rRkhyIi0qEwYzH9DqgGioH6+IbTu+0or+Gp1Xv56MX5\n5I0ckuxwREQ6FCZB5Lr7gs6rSWceeGYrQwf01+xwItIjhGmD+OupDMEtsb32ZgXPbz7I7XMnM3LY\nwGSHIyLSqTBnEJcBt5rZm0QuMbUOtXFuXCPrRSJDamxm1PCB3HbpxGSHIyISSpgEcW3co+jlnn3j\nAK/vqeLBG89h8AANqSEiPUOnl5jcvQTIAK4PHhlBmYTQ2NzCQyu2MnXUMA2pISI9SqcJwszuBp4A\ncoLHT83srngH1ls8+doe3jx8nC8tOIv+Kep2IiI9R5hLTB8HLnL34wBm9iDwMvCf8QysNzhW38TD\nz2/nookjePdZOckOR0TklIRJEAY0Ry03B2XSiSUv7eLI8Qb+57qzNaSGiPQ4YRLEY8CrZvbbYPn9\nwP/EL6TeofxoHT94aRfvPXcM54/XkBoi0vOEaaT+d+BjQEXw+Ji7Pxzmzc1sgZltNbMdZnZvjPW3\nmtkhM1sbPD4Rta45qnxZ+I/UPTy8cjuNzS0aUkNEeqwwZxC4+xpgzam8sZmlAI8C84BSYLWZLXP3\nTW2qPuXud8Z4i1p3P/9U9tld7Cg/xlOr9/KRd00gP2tossMRETkt8byt5kJgh7vvcvcG4Enghjju\nr9t46NktDE5N0ZAaItKjxTNBjAP2Ri2XBmVt3Whm683sV2Y2Pqp8kJkVmdkrZvb+WDsws8VBnaJD\nhw51Yeinr2h3BX/cdJDbr5ykITVEpEcL0w/iLjPLjNP+fw/kB8N2PAc8HrVugrsXAjcDD5vZ5LYb\nu/sSdy9098Ls7OTPzObufHv5ZnLSBnLbZRpSQ0R6tjBnEKOItB/8Imh0Dnu/ZhkQfUaQG5Sd5O5H\n3L11CPEfAnOi1pUFz7uAF4FZIfebNCs2HmTNnio+N28qQwaEat4REem2wtzF9BWggMitrbcC283s\n27H+R9/GaqDAzCaa2QBgEfC2u5HMbEzU4kJgc1CeGUxUhJllAZcCbRu3u5XG5hYeenYLU3KG8Tdz\nNKSGiPR8Ye9icjM7ABwAmoBM4Fdm9py7f7GdbZrM7E5gBZACLHX3jWZ2H1Dk7suAT5vZwuA9K4gk\nIICzge+bWQuRJPZAjLufupWnVu9l1+Hj/PCjhRpSQ0R6BXP3jitExmL6KHCYyGWgp9290cz6Advd\nvbMziYQoLCz0oqKipOz7eH0TV/7Li0zKGspTf/8u9ZoWkR7DzIqD9t53CHMGMQL4YNsRXN29xcze\n1xUB9nQ/+PMuDh+rZ8lH5yg5iEivEeZayDNELv8AYGbDzewiAHffHK/AeooTDU0seWkX150zmtl5\n8brZS0Qk8cIkiO8Bx6KWjwVlAqzdU8WJhmY+XDi+88oiIj1ImARhHtVQ4e4thGzc7guKSyoxg1k6\nexCRXiZMgthlZp82s9TgcTewK96B9RRFJZVMzUkjfXBqskMREelSYRLE7cAlRDq5lQIXAYvjGVRP\n0dLirNlTyZx8nT2ISO/T6aUidy8n0slN2thefoyauibm6PKSiPRCnSYIMxtEZNrRGcCg1nJ3vy2O\ncfUIxSWVAMyZoAQhIr1PmEtMPwFGA+8B/kRkTKWaeAbVUxSVVJA1bAATRg5JdigiIl0uTIKY4u5f\nBY67++PAe4m0Q/R5a0oqmZ2Xqc5xItIrhUkQjcFzlZnNBNKBnPiF1DMcqqln95ETFKqBWkR6qTD9\nGZYE80F8hchorMOAr8Y1qh5gzR61P4hI79ZhgggG5Dvq7pXAS8CkhETVA6wpqWRASj9mjE1Pdigi\nInHR4SWmoNd0zOG8+7qikkrOyU1nUGpKskMREYmLMG0Qz5vZF8xsvJmNaH3EPbJurL6pmQ2l1bq8\nJCK9Wpg2iL8Nnu+IKnP68OWmN8qqaWhuUYIQkV4tTE/qiYkIpCdp7SCn4b1FpDcL05P6o7HK3f3H\nXR9Oz1C0u5L8kUPIThuY7FBEROImTBvEBVGPy4GvAwvDvLmZLTCzrWa2w8zujbH+VjM7ZGZrg8cn\notbdYmbbg8ctoT5NArhHBuibrctLItLLhbnEdFf0spllAE92tp2ZpQCPAvOIjAK72syWufumNlWf\ncvc722w7AvgnoJBIe0dxsG1lZ/uNt5IjJzh8rEHtDyLS64U5g2jrOBCmXeJCYIe773L3BiJJ5YaQ\n+3gP8Jy7VwRJ4TlgwWnE2uVa2x8KJ/TpG7lEpA8I0wbxeyL/i4dIQpkO/CLEe48D9kYtt84l0daN\nZnYFsA34rLvvbWfbcSH2GXfFeypJG9SfgpxhyQ5FRCSuwtzm+q9Rr5uAEncv7aL9/x74ubvXm9nf\nA48D7w67sZktJpi8KC8vr4tC6ljx7sgAff36aYA+Eendwlxi2gO86u5/cve/AEfMLD/EdmXA+Kjl\n3KDsJHc/4u71weIPgTlhtw22X+Luhe5emJ2dHSKkM1Nd28i28hq1P4hInxAmQfwSaIlabg7KOrMa\nKDCziWY2gMisdMuiK5jZmKjFhcDm4PUKYL6ZZQYDBc4PypLq9T2VuEOhEoSI9AFhLjH1DxqZAXD3\nhuCA3yF3bzKzO4kc2FOApe6+0czuA4rcfRnwaTNbSOTSVQVwa7BthZl9g0iSAbjP3StO5YPFw5qS\nSvoZnDc+I9mhiIjEXZgEccjMFgYHdMzsBuBwmDd39+XA8jZlX4t6/WXgy+1suxRYGmY/iVJUUsnZ\nY4YzdGCYr01EpGcLc6S7He5Qf0UAAAzuSURBVHjCzL4bLJcCMXtX92ZNzS2s3VvFh+bkJjsUEZGE\nCNNRbifwLjMbFiwfi3tU3dCWAzWcaGhWD2oR6TM6baQ2s2+bWYa7H3P3Y0HD8TcTEVx3crKDXL46\nyIlI3xDmLqZr3b2qdSHo2Xxd/ELqnopLKhk9fBBj0wclOxQRkYQIkyBSzOzksKVmNhjoc8OYFpdU\nMic/EzN1kBORviFMgngCWGlmHzezjxMZF6lPDfW9v7qWsqpa5mj+BxHpQ8I0Uj9oZuuAa4Kib7h7\n0jutJVJr+4N6UItIXxLqhn53fxZ4FsDMLjOzR939jk426zWKSyoZlNqP6WOHJzsUEZGECZUgzGwW\ncBPwYeBN4DfxDKq7KS6p5LzcDFJTTmd0dBGRnqndBGFmU4kkhZuI9Jx+CjB3vypBsXULJxqa2Ljv\nKLdfOSnZoYiIJFRHZxBbgD8D73P3HQBm9tmERNWNrC+tprnF1f4gIn1OR9dMPgjsB1aZ2Q/M7Gqg\nz93j2dpAPVt3MIlIH9NugnD3p919EXAWsAr4DJBjZt8zs/mJCjDZiksqmZIzjIwhnQ5gKyLSq3Ta\n6urux939Z+5+PZGJe14HvhT3yLqBlhaPdJDT2YOI9EGndFuOu1cGs7hdHa+AupNdh49RXdvInHwl\nCBHpe3TfZgeKdquDnIj0XUoQHSguqSRzSCqTsoYmOxQRkYRTguhAcUklcyZogD4R6ZuUINpRcbyB\nXYePa4IgEemz4pogzGyBmW01sx1mdm8H9W40MzezwmA538xqzWxt8PjveMYZy5rWCYImaIIgEemb\nQo3FdDrMLAV4FJhHZB7r1Wa2zN03tamXBtwNvNrmLXa6+/nxiq8zRSWVpKYY5+amJysEEZGkiucZ\nxIXADnff5e4NwJPADTHqfQN4EKiLYyynbE1JJTPGpjMoNSXZoYiIJEU8E8Q4YG/UcmlQdpKZzQbG\nu/sfYmw/0cxeN7M/mdnlsXZgZovNrMjMig4dOtRlgTc0tbCutEq3t4pIn5a0Rmoz6wf8O/D5GKv3\nA3nuPgv4HPAzM3vHZAxBp71Cdy/Mzs7ustg27qumvqmFQiUIEenD4pkgyoDxUcu5QVmrNGAm8KKZ\n7QbeBSwzs0J3r3f3IwDuXgzsBKbGMda3OTlAnxKEiPRh8UwQq4ECM5toZgOARcCy1pXuXu3uWe6e\n7+75wCvAQncvMrPsoJEbM5sEFAC74hjr2xSXVJKbOZhRwwclapciIt1O3O5icvcmM7sTWAGkAEvd\nfaOZ3QcUufuyDja/ArjPzBqBFuB2d6+IV6zR3J2ikkounTwyEbsTEem24pYgANx9ObC8TdnX2qk7\nN+r1r4FfxzO29pRW1nKopl4N1CLS56kndRut7Q9z1EFORPo4JYg2ikoqGDoghWmj05IdiohIUilB\ntFFcUsWsvExS+mmAPhHp25QgotTUNbL1wFG1P4iIoATxNmv3VtHimiBIRASUIN6maHclZjArLyPZ\noYiIJJ0SRJQ1eyqZNiqNtEGpyQ5FRCTplCACzS3O63uqKMzX5SUREVCCOGnrgRqO1Tep/UFEJKAE\nESjeE3SQy1MHORERUII4qXh3BdlpAxk/YnCyQxER6RaUIALFeyqZk5eJmTrIiYiAEgQA5Ufr2FtR\nqwZqEZEoShBogiARkViUIICikkoG9O/HzLHpyQ5FRKTbUIIgcgZxXm46A/rr6xARadXnj4h1jc1s\n3Fety0siIm30+QRxtK6Ra2eO4YqC7GSHIiLSrcQ1QZjZAjPbamY7zOzeDurdaGZuZoVRZV8Otttq\nZu+JV4w5aYN45KZZXDolK167EBHpkeI2J7WZpQCPAvOAUmC1mS1z901t6qUBdwOvRpVNBxYBM4Cx\nwPNmNtXdm+MVr4iIvF08zyAuBHa4+y53bwCeBG6IUe8bwINAXVTZDcCT7l7v7m8CO4L3ExGRBIln\nghgH7I1aLg3KTjKz2cB4d//DqW4bbL/YzIrMrOjQoUNdE7WIiABJbKQ2s37AvwOfP933cPcl7l7o\n7oXZ2WpkFhHpSnFrgwDKgPFRy7lBWas0YCbwYjD+0WhgmZktDLGtiIjEWTzPIFYDBWY20cwGEGl0\nXta60t2r3T3L3fPdPR94BVjo7kVBvUVmNtDMJgIFwGtxjFVERNqI2xmEuzeZ2Z3ACiAFWOruG83s\nPqDI3Zd1sO1GM/sFsAloAu7QHUwiIoll7p7sGLpEYWGhFxUVJTsMEZEexcyK3b0w5rrekiDM7BBQ\nkuw4OpAFHE52EB1QfGdG8Z0ZxXdmziS+Ce4e8y6fXpMgujszK2ovS3cHiu/MKL4zo/jOTLzi6/Nj\nMYmISGxKECIiEpMSROIsSXYAnVB8Z0bxnRnFd2biEp/aIEREJCadQYiISExKECIiEpMSRBcxs/Fm\ntsrMNpnZRjO7O0aduWZWbWZrg8fXkhDnbjPbEOz/HT0LLeKRYLKm9cGIu4mKbVrUd7PWzI6a2Wfa\n1Enod2hmS82s3MzeiCobYWbPmdn24DnmfLVmdktQZ7uZ3ZLA+P7FzLYE/36/NbOMdrbt8LcQx/i+\nbmZlUf+G17WzbagJx+IQ31NRse02s7XtbJuI7y/mcSVhv0F316MLHsAYYHbwOg3YBkxvU2cu8L9J\njnM3kNXB+uuAZwAD3gW8mqQ4U4ADRDrxJO07BK4AZgNvRJU9BNwbvL4XeDDGdiOAXcFzZvA6M0Hx\nzQf6B68fjBVfmN9CHOP7OvCFEP/+O4FJwABgXdu/p3jF12b9vwFfS+L3F/O4kqjfoM4guoi773f3\nNcHrGmAzMeaw6AFuAH7sEa8AGWY2JglxXA3sdPek9o5395eAijbFNwCPB68fB94fY9P3AM+5e4W7\nVwLPAQsSEZ+7/9Hdm4LFV4iMhpwU7Xx/YYSdcOyMdBSfRYaZ/jDw867eb1gdHFcS8htUgogDM8sH\nZhE1jWqUi81snZk9Y2YzEhpYhAN/NLNiM1scY32oyZoSYBHt/2Em+zsc5e77g9cHgFEx6nSX7/E2\nImeEsXT2W4inO4NLYEvbuTzSHb6/y4GD7r69nfUJ/f7aHFcS8htUguhiZjYM+DXwGXc/2mb1GiKX\nTM4D/hN4OtHxAZe5+2zgWuAOM7siCTF0yCLDwy8EfhljdXf4Dk/yyLl8t7xX3Mz+H5HRkJ9op0qy\nfgvfAyYD5wP7iVzG6Y5uouOzh4R9fx0dV+L5G1SC6EJmlkrkH/EJd/9N2/XuftTdjwWvlwOpZpaV\nyBjdvSx4Lgd+yzvn+u4OkzVdC6xx94NtV3SH7xA42HrZLXguj1Enqd+jmd0KvA/4u+AA8g4hfgtx\n4e4H3b3Z3VuAH7Sz32R/f/2BDwJPtVcnUd9fO8eVhPwGlSC6SHC98n+Aze7+7+3UGR3Uw8wuJPL9\nH0lgjEPNLK31NZHGzDfaVFsGfDS4m+ldQHXUqWyitPs/t2R/h4FlQOsdIbcAv4tRZwUw38wyg0so\n84OyuDOzBcAXiUzAdaKdOmF+C/GKL7pN6wPt7LfDCccS4Bpgi7uXxlqZqO+vg+NKYn6D8WyB70sP\n4DIip3nrgbXB4zrgduD2oM6dwEYid2S8AlyS4BgnBfteF8Tx/4Ly6BgNeJTIHSQbgMIExziUyAE/\nPaosad8hkUS1H2gkcg3348BIYCWwHXgeGBHULQR+GLXtbcCO4PGxBMa3g8i159bf4X8HdccCyzv6\nLSQovp8Ev631RA50Y9rGFyxfR+SunZ2JjC8o/1Hrby6qbjK+v/aOKwn5DWqoDRERiUmXmEREJCYl\nCBERiUkJQkREYlKCEBGRmJQgREQkJiUIkU6YWbO9fZTZLhtZ1Mzyo0cSFelO+ic7AJEeoNbdz092\nECKJpjMIkdMUzAfwUDAnwGtmNiUozzezF4LB6FaaWV5QPsoi8zOsCx6XBG+VYmY/CMb7/6OZDQ7q\nfzqYB2C9mT2ZpI8pfZgShEjnBre5xPS3Ueuq3f0c4LvAw0HZfwKPu/u5RAbKeyQofwT4k0cGGpxN\npAcuQAHwqLvPAKqAG4Pye4FZwfvcHq8PJ9Ie9aQW6YSZHXP3YTHKdwPvdvddwYBqB9x9pJkdJjJ8\nRGNQvt/ds8zsEJDr7vVR75FPZMz+gmD5S0Cqu3/TzJ4FjhEZsfZpDwYpFEkUnUGInBlv5/WpqI96\n3cxbbYPvJTIu1mxgdTDCqEjCKEGInJm/jXp+OXj9VyKjjwL8HfDn4PVK4FMAZpZiZuntvamZ9QPG\nu/sq4EtAOvCOsxiReNL/SEQ6N9jePnH9s+7eeqtrppmtJ3IWcFNQdhfwmJndAxwCPhaU3w0sMbOP\nEzlT+BSRkURjSQF+GiQRAx5x96ou+0QiIagNQuQ0BW0Qhe5+ONmxiMSDLjGJiEhMOoMQEZGYdAYh\nIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjH9f0a3MfdOLiBtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYaVowXBCwtF",
        "colab_type": "text"
      },
      "source": [
        "## Close the session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT5BJO9BCwtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "session.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYTHNa_UCwtH",
        "colab_type": "text"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-25YKjHCwtI",
        "colab_type": "text"
      },
      "source": [
        "In this part of the 3rd question the network given in the figure is implemented using the 'high' level API\n",
        "functions. Inputs are divided by 255 in order to place the numbers between 0-1. Dividing by 255 was rooted from the fact that inputs are\n",
        "pixel values of images. System consists of total a total of 3 convolution layers, 3 pooling layers each are placed after\n",
        "a convolution layer. After the third pooling layer 2 fully connected layers are present. Fully connected\n",
        "layers have 128 and 10 neurons respectively. Outside the network, a softmax activation function completes the \n",
        "network's guess for each image. Input size is not changed in conv. layers but downsampled to half of the input'size\n",
        "size in each pooling layers. \n",
        "\n",
        "In network definition, pooling type is not specified, AVG pooling is choosen in order to\n",
        "reduce information loss between layers. In max pooling final train_acc,test_acc = [0.71, 0.71],  while the\n",
        "final train_acc, test_acc = [0.72, 0.72] in average pooling, after 10 epochs. Here and later \"computation time\"\n",
        "refers to neither training, nor test time but a mixture of them. Time is calculated the execution duration of the 14th cell\n",
        "given by Google CoLab when mouse is hovered on the 'play' button, hw accelerator is choosen as GPU. Computation time of each \n",
        "option resulted around 65 seconds.\n",
        "\n",
        "However, both of the implementations' lower API versions resulted in a shorter computation duration of\n",
        "50 seconds. This is due to fact that lower level API gives more work for the programmer but it is purified from the overheads of\n",
        "high-level functions. In general, it can be said that, lower level API can result in faster implementation.\n",
        "\n",
        "Another unspecified point was the batch size, with batch_size 128, computation time for 10 epochs is ~65secs. and \n",
        "final test acc. is aroung 72%. When batch_size is reduced to 32, computation time for 10 epochs increased to 120 secs. while\n",
        "final test acc. increased to 73%. One reason of the accuracy increase [1] can be the fact that smaller batch sizes are noisy, \n",
        "offering a regularizing effect and lower generalization error.\n",
        "\n",
        "Dropout is implemented by using different dropout rates for test and training feed_dict's. Original dropout rates are \n",
        "0.4 and 0.01 for train and test respectively. When dropout is set to 0.99 for each function,test accuracy decreased to 0.1\n",
        "network doesn't learn anything during training and 1st fully connected layer neurons are not working, guess is completely randomized by output neurons.\n",
        "Later dropout is set to 0.99 and 0.01 for training and test respectively final test result was again 0.1. This time neurons were on for inference but,\n",
        "they were off while training hence, no learning observed. Turning off the neurons (dropout = 0.99 in both) did not changed the computation time.\n",
        "\n",
        "When epoch number is increased to 20 from 10, final test accuracy also increased to 76%.Moreover, computation time is also \n",
        "increased to 120 secs.\n",
        "\n",
        "When we bypass the batch_normalization, final test accuracy drop to 66% from 76% in 20 epochs. Moreover, computation\n",
        "time is decreased to 110 seconds since network's computation cost is decreased.\n",
        "\n",
        "[1] https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRjg7b97CwtJ",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[1] [Arm Community](https://community.arm.com)\n",
        "\n",
        "[2] https://r2rt.com/implementing-batch-normalization-in-tensorflow.html\n",
        "\n",
        "[3] https://gist.github.com/andrewkruger/d62faac06f950c4388d9b23aae0c9cc9#file-gistfile1-txt\n",
        "\n",
        "[4] https://github.com/METU-MMI-DeepLearning/MMI713_Deep_Learning/blob/master/Lab1.ipynb"
      ]
    }
  ]
}